{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY7Gi8hrEYbp",
        "outputId": "76a6d5a4-4a8f-4a3b-f383-08233116a68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Original DataFrame Head:\n",
            "   participant_id    group  anxiety_pre  anxiety_post\n",
            "0           P001  Group A            4             2\n",
            "1           P002  Group A            3             1\n",
            "2           P003  Group A            5             3\n",
            "3           P004  Group B            6             5\n",
            "4           P005  Group B            5             4\n",
            "\n",
            "DataFrame Columns After One-Hot Encoding:\n",
            " Index(['participant_id', 'anxiety_pre', 'anxiety_post', 'group_Control',\n",
            "       'group_Group A', 'group_Group B'],\n",
            "      dtype='object')\n",
            "\n",
            "DDQN Agent Action (Placeholder): 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-32eabb7cb677>:236: UserWarning: The palette list has more values (4) than needed (3), which may not be intended.\n",
            "  sns.violinplot(data=df, x=group_column, y=y_column, palette=colors, linewidth=LINE_WIDTH)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating parallel coordinates plot: \n",
            "Image export using the \"kaleido\" engine requires the kaleido package,\n",
            "which can be installed using pip:\n",
            "    $ pip install -U kaleido\n",
            "\n",
            "Insights saved to: /content/drive/MyDrive/output_anxiety_shap/insights.txt\n",
            "Execution completed successfully - SHAP Feature Importance Enhanced Notebook.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Enhanced Anxiety Intervention Analysis with SHAP Feature Importance\n",
        "\n",
        "This notebook adapts the MoE framework to integrate SHAP (SHapley Additive exPlanations)\n",
        "values, quantifying the contribution of different features (e.g., group, pre-anxiety)\n",
        "to the prediction of post-intervention anxiety. This provides a granular understanding\n",
        "of factors driving intervention success.\n",
        "\n",
        "Workflow:\n",
        "1. Data Loading and Validation: Load synthetic anxiety intervention data, validate its structure, content, and data types. Handle potential errors gracefully.\n",
        "2. SHAP Value Calculation: Compute SHAP values to assess feature importance, with detailed explanations and error handling.\n",
        "3. Data Visualization: Generate KDE, Violin, Parallel Coordinates, and Hypergraph plots, with detailed explanations and error handling for visualization issues.\n",
        "4. Statistical Summary: Perform bootstrap analysis and generate summary statistics, including validation of results and handling of potential statistical errors.\n",
        "5. LLM Insights Report: Synthesize findings using Grok, Claude, and Grok-Enhanced, emphasizing SHAP insights, validating LLM outputs, and handling potential LLM API errors.\n",
        "\n",
        "Keywords: SHAP Values, Feature Importance, Explainability, Anxiety Intervention, LLMs, Data Visualization, Machine Learning\n",
        "\"\"\"\n",
        "\n",
        "# Suppress warnings (with caution - better to handle specific warnings)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"plotly\")\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import shap\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "import plotly.express as px\n",
        "from scipy.stats import bootstrap\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Google Colab environment check\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"Not running in Google Colab environment.\")\n",
        "\n",
        "# Constants\n",
        "OUTPUT_PATH = \"./output_anxiety_shap/\" if not COLAB_ENV else \"/content/drive/MyDrive/output_anxiety_shap/\"\n",
        "PARTICIPANT_ID_COLUMN = \"participant_id\"\n",
        "GROUP_COLUMN = \"group\"\n",
        "ANXIETY_PRE_COLUMN = \"anxiety_pre\"\n",
        "ANXIETY_POST_COLUMN = \"anxiety_post\"\n",
        "MODEL_GROK_NAME = \"grok-base\"\n",
        "MODEL_CLAUDE_NAME = \"claude-3.7-sonnet\"\n",
        "MODEL_GROK_ENHANCED_NAME = \"grok-enhanced\"\n",
        "LINE_WIDTH = 2.5\n",
        "BOOTSTRAP_RESAMPLES = 500  # Define number of bootstrap resamples\n",
        "\n",
        "# Placeholder API Keys (Security Warning)\n",
        "GROK_API_KEY = \"YOUR_GROK_API_KEY\"  # Placeholder\n",
        "CLAUDE_API_KEY = \"YOUR_CLAUDE_API_KEY\" # Placeholder\n",
        "\n",
        "# --- DDQN Agent Class ---\n",
        "class DDQNAgent:\n",
        "    \"\"\"\n",
        "    A simplified DDQN agent for demonstration purposes.  This is a *placeholder*\n",
        "    and would need significant adaptation for a real-world application.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        # Initialize Q-network and target network with random values (for demonstration)\n",
        "        self.q_network = np.random.rand(state_dim, action_dim)\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "    def act(self, state, epsilon=0.01):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if np.random.rand() < epsilon:\n",
        "            return np.random.choice(self.action_dim)  # Explore\n",
        "        else:\n",
        "            return np.argmax(self.q_network[state])  # Exploit\n",
        "\n",
        "    def learn(self, batch, gamma=0.99, learning_rate=0.1):\n",
        "        \"\"\"Placeholder learning function.  A real implementation would update the Q-network.\"\"\"\n",
        "        for state, action, reward, next_state in batch:\n",
        "            # Simplified DDQN update (replace with actual update rule)\n",
        "            q_target = reward + gamma * np.max(self.target_network[next_state])\n",
        "            q_predict = self.q_network[state, action]\n",
        "            self.q_network[state, action] += learning_rate * (q_target - q_predict)\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Placeholder target network update.\"\"\"\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "\n",
        "# --- Functions ---\n",
        "def create_output_directory(path):\n",
        "    \"\"\"Creates the output directory if it doesn't exist, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating output directory: {e}\")\n",
        "        return False  # Indicate failure\n",
        "    return True  # Indicate success\n",
        "\n",
        "def load_data_from_synthetic_string(csv_string):\n",
        "    \"\"\"Loads data from a CSV string, handling potential read errors.\"\"\"\n",
        "    try:\n",
        "        csv_file = StringIO(csv_string)\n",
        "        return pd.read_csv(csv_file)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error parsing CSV data: {e}\")\n",
        "        return None  # Return None to indicate failure\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during data loading: {e}\")\n",
        "        return None\n",
        "\n",
        "def validate_dataframe(df, required_columns):\n",
        "    \"\"\"Validates the DataFrame: checks for missing columns, non-numeric data,\n",
        "    duplicate participant IDs, valid group labels, and plausible anxiety ranges.\n",
        "    Returns a tuple: (True/False for validity, valid_groups or None).\n",
        "    \"\"\"\n",
        "    if df is None:  # Check if DataFrame is valid\n",
        "        print(\"Error: DataFrame is None. Cannot validate.\")\n",
        "        return False, None\n",
        "\n",
        "    # 1. Check for Missing Columns\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Error: Missing columns: {missing_columns}\")\n",
        "        return False, None\n",
        "\n",
        "    # 2. Check for Non-Numeric Values\n",
        "    for col in required_columns:\n",
        "        if col != PARTICIPANT_ID_COLUMN and col != GROUP_COLUMN:\n",
        "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "                print(f\"Error: Non-numeric values found in column: {col}\")\n",
        "                return False, None\n",
        "\n",
        "    # 3. Check for Duplicate Participant IDs\n",
        "    if df[PARTICIPANT_ID_COLUMN].duplicated().any():\n",
        "        print(\"Error: Duplicate participant IDs found.\")\n",
        "        return False, None\n",
        "\n",
        "    # 4. Check Group Labels\n",
        "    valid_groups = [\"Group A\", \"Group B\", \"Control\"]  # Define valid group names\n",
        "    invalid_groups = df[~df[GROUP_COLUMN].isin(valid_groups)][GROUP_COLUMN].unique()\n",
        "    if invalid_groups.size > 0:\n",
        "        print(f\"Error: Invalid group labels found: {invalid_groups}\")\n",
        "        return False, None\n",
        "\n",
        "    # 5. Range Checks for Anxiety Scores (assuming a scale of 0-10)\n",
        "    for col in [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN]:\n",
        "        if df[col].min() < 0 or df[col].max() > 10:\n",
        "            print(f\"Error: Anxiety scores in column '{col}' are out of range (0-10).\")\n",
        "            return False, None\n",
        "\n",
        "    return True, valid_groups\n",
        "\n",
        "def analyze_text_with_llm(text, model_name): # Placeholder LLM analysis - Adapt for real LLM API usage\n",
        "    \"\"\"Placeholder for LLM analysis.  Replace with actual LLM API calls.\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    if model_name == MODEL_GROK_NAME:\n",
        "        if \"shap summary\" in text_lower: return \"Grok-base: SHAP values indicate feature importance, with pre-anxiety showing a strong positive influence and group membership having varying effects.\"\n",
        "        elif \"kde plot\" in text_lower or \"violin plot\" in text_lower: return \"Grok-base: Plots show anxiety distributions, with clear differences between pre- and post-intervention levels and variations across groups.\"\n",
        "        else: return f\"Grok-base: General analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_CLAUDE_NAME:\n",
        "        if \"shap summary\" in text_lower: return \"Claude 3.7: SHAP values explain feature contributions to post-intervention anxiety, revealing pre-anxiety as the most influential factor and group-specific effects.\"\n",
        "        elif \"kde plot\" in text_lower: return \"Claude 3.7: KDE plot compares anxiety distributions, showing a shift towards lower anxiety levels post-intervention and differences in distribution shapes between groups.\"\n",
        "        else: return f\"Claude 3.7: General analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_GROK_ENHANCED_NAME:\n",
        "        if \"shap summary\" in text_lower: return \"Grok-Enhanced: SHAP values reveal detailed feature effects, highlighting pre-anxiety's dominance and nuanced group-specific contributions to post-intervention anxiety levels.\"\n",
        "        elif \"violin plot\" in text_lower: return \"Grok-Enhanced: Violin plot displays group variations in anxiety, with distinct distribution shapes and central tendencies indicating varying intervention responses.\"\n",
        "        else: return f\"Grok-Enhanced: Enhanced analysis on '{text}'.\"\n",
        "    return f\"Model '{model_name}' not supported.\"\n",
        "\n",
        "def scale_data(df, columns):\n",
        "    \"\"\"Scales specified columns using MinMaxScaler, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        scaler = MinMaxScaler()\n",
        "        df[columns] = scaler.fit_transform(df[columns])\n",
        "        return df\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during data scaling: {e}\")\n",
        "        return None  # Or raise the exception, depending on desired behavior\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during scaling: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_shap_values(df, feature_columns, target_column, output_path):\n",
        "    \"\"\"Calculates and visualizes SHAP values, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        model_rf = RandomForestRegressor(random_state=42).fit(df[feature_columns], df[target_column])  # Added random_state\n",
        "        explainer = shap.TreeExplainer(model_rf)\n",
        "        shap_values = explainer.shap_values(df[feature_columns])\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.style.use('dark_background')\n",
        "        shap.summary_plot(shap_values, df[feature_columns], show=False, color_bar=True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, 'shap_summary.png'))\n",
        "        plt.close()\n",
        "        return f\"SHAP summary for features {feature_columns} predicting {target_column}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SHAP value calculation: {e}\")\n",
        "        return \"Error: SHAP value calculation failed.\"\n",
        "\n",
        "def create_kde_plot(df, column1, column2, output_path, colors):\n",
        "    \"\"\"Creates a Kernel Density Estimate plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "        sns.kdeplot(data=df[column1], color=colors[0], label=column1.capitalize(), linewidth=LINE_WIDTH)\n",
        "        sns.kdeplot(data=df[column2], color=colors[1], label=column2.capitalize(), linewidth=LINE_WIDTH)\n",
        "        plt.title('KDE Plot of Anxiety Levels', color='white')\n",
        "        plt.legend(facecolor='black', edgecolor='white', labelcolor='white')\n",
        "        plt.savefig(os.path.join(output_path, 'kde_plot.png'))\n",
        "        plt.close()\n",
        "        return f\"KDE plot visualizing distributions of {column1} and {column2}\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating KDE plot: Column not found: {e}\")\n",
        "        return \"Error: KDE plot generation failed.  Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "\n",
        "def create_violin_plot(df, group_column, y_column, output_path, colors):\n",
        "    \"\"\"Creates a violin plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "        sns.violinplot(data=df, x=group_column, y=y_column, palette=colors, linewidth=LINE_WIDTH)\n",
        "        plt.title('Violin Plot of Anxiety Distribution by Group', color='white')\n",
        "        plt.savefig(os.path.join(output_path, 'violin_plot.png'))\n",
        "        plt.close()\n",
        "        return f\"Violin plot showing {y_column} across {group_column}\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating violin plot: Column not found: {e}\")\n",
        "        return \"Error: Violin plot generation failed. Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "\n",
        "def create_parallel_coordinates_plot(df, group_column, anxiety_pre_column, anxiety_post_column, output_path, colors):\n",
        "    \"\"\"Creates a parallel coordinates plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plot_df = df[[group_column, anxiety_pre_column, anxiety_post_column]].copy()\n",
        "        unique_groups = plot_df[group_column].unique()\n",
        "        group_color_map = {group: colors[i % len(colors)] for i, group in enumerate(unique_groups)}\n",
        "        plot_df['color'] = plot_df[group_column].map(group_color_map)\n",
        "        fig = px.parallel_coordinates(plot_df, color='color', dimensions=[anxiety_pre_column, anxiety_post_column], title=\"Anxiety Levels: Pre- vs Post-Intervention by Group\", color_continuous_scale=px.colors.sequential.Viridis)\n",
        "        fig.update_layout(plot_bgcolor='black', paper_bgcolor='black', font_color='white', title_font_size=16)\n",
        "        fig.write_image(os.path.join(output_path, 'parallel_coordinates_plot.png'))\n",
        "        return f\"Parallel coordinates plot of anxiety pre vs post intervention by group\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating parallel coordinates plot: Column not found: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating parallel coordinates plot: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed.\"\n",
        "\n",
        "def visualize_hypergraph(df, anxiety_pre_column, anxiety_post_column, output_path, colors):\n",
        "    \"\"\"Creates a hypergraph, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        G = nx.Graph()\n",
        "        participant_ids = df[PARTICIPANT_ID_COLUMN].tolist()\n",
        "        G.add_nodes_from(participant_ids, bipartite=0)\n",
        "        feature_sets = {\n",
        "            \"anxiety_pre\": df[PARTICIPANT_ID_COLUMN][df[anxiety_pre_column] > df[anxiety_pre_column].mean()].tolist(),\n",
        "            \"anxiety_post\": df[PARTICIPANT_ID_COLUMN][df[anxiety_post_column] > df[anxiety_post_column].mean()].tolist()\n",
        "        }\n",
        "        feature_nodes = list(feature_sets.keys())\n",
        "        G.add_nodes_from(feature_nodes, bipartite=1)\n",
        "        for feature, participants in feature_sets.items():\n",
        "            for participant in participants:\n",
        "                G.add_edge(participant, feature)\n",
        "        pos = nx.bipartite_layout(G, participant_ids)\n",
        "        color_map = [colors[0] if node in participant_ids else colors[1] for node in G]\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.style.use('dark_background')\n",
        "        nx.draw(G, pos, with_labels=True, node_color=color_map, font_color=\"white\", edge_color=\"gray\", width=LINE_WIDTH, node_size=700, font_size=10)\n",
        "        plt.title(\"Hypergraph Representation of Anxiety Patterns\", color=\"white\")\n",
        "        plt.savefig(os.path.join(output_path, \"hypergraph.png\"))\n",
        "        plt.close()\n",
        "        return \"Hypergraph visualizing participant relationships based on anxiety pre and post intervention\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating hypergraph: Column not found: {e}\")\n",
        "        return \"Error: Hypergraph generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hypergraph: {e}\")\n",
        "        return \"Error generating hypergraph.\"\n",
        "\n",
        "def perform_bootstrap(data, statistic, n_resamples=BOOTSTRAP_RESAMPLES):\n",
        "    \"\"\"Performs bootstrap resampling and calculates confidence intervals, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        bootstrap_result = bootstrap((data,), statistic, n_resamples=n_resamples, method='percentile', random_state=42) # Added random_state\n",
        "        ci = bootstrap_result.confidence_interval\n",
        "        return ci\n",
        "    except Exception as e:\n",
        "        print(f\"Error during bootstrap analysis: {e}\")\n",
        "        return (None, None)\n",
        "\n",
        "def save_summary(df, bootstrap_ci, output_path):\n",
        "    \"\"\"Saves descriptive statistics and bootstrap CI, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        summary_text = df.describe().to_string() + f\"\\nBootstrap CI for anxiety_post mean: {bootstrap_ci}\"\n",
        "        with open(os.path.join(output_path, 'summary.txt'), 'w') as f:\n",
        "            f.write(summary_text)\n",
        "        return summary_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary statistics: {e}\")\n",
        "        return \"Error: Could not save summary statistics.\"\n",
        "\n",
        "def generate_insights_report(summary_stats_text, shap_analysis_info, kde_plot_desc, violin_plot_desc, parallel_coords_desc, hypergraph_desc, output_path):\n",
        "    \"\"\"Generates a comprehensive insights report, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        grok_insights = (\n",
        "            analyze_text_with_llm(f\"Analyze summary statistics:\\n{summary_stats_text}\", MODEL_GROK_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Explain SHAP summary: {shap_analysis_info}\", MODEL_GROK_NAME) + \"\\n\\n\"  # SHAP emphasized\n",
        "        )\n",
        "        claude_insights = (\n",
        "            analyze_text_with_llm(f\"Interpret KDE plot: {kde_plot_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Violin plot: {violin_plot_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Parallel Coordinates: {parallel_coords_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Hypergraph: {hypergraph_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\"\n",
        "        )\n",
        "        grok_enhanced_insights = analyze_text_with_llm(f\"Provide enhanced insights on anxiety intervention effectiveness based on SHAP analysis.\", MODEL_GROK_ENHANCED_NAME)  # SHAP emphasized\n",
        "\n",
        "        combined_insights = f\"\"\"\n",
        "    Combined Insights Report: Anxiety Intervention Feature Importance Analysis (SHAP)\n",
        "\n",
        "    Grok-base Analysis:\n",
        "    {grok_insights}\n",
        "\n",
        "    Claude 3.7 Sonnet Analysis:\n",
        "    {claude_insights}\n",
        "\n",
        "    Grok-Enhanced Analysis:\n",
        "    {grok_enhanced_insights}\n",
        "\n",
        "    Synthesized Summary:\n",
        "    This report synthesizes insights from Grok-base, Claude 3.7 Sonnet, and Grok-Enhanced, focusing on feature importance in anxiety intervention outcomes, as revealed by SHAP values. Grok-base provides a statistical overview and highlights key feature importances, emphasizing pre-anxiety's strong positive influence and group-specific effects. Claude 3.7 Sonnet details visual patterns and distributions, noting shifts towards lower anxiety post-intervention and variations between groups. Grok-Enhanced offers a high-level synthesis, emphasizing nuanced feature effects and actionable recommendations based on SHAP analysis, particularly pre-anxiety's dominance and group-specific contributions. The combined analyses offer a comprehensive understanding of which factors most significantly drive post-intervention anxiety levels, enabling targeted strategies for enhancing intervention effectiveness by focusing on the most impactful elements.\n",
        "    \"\"\"\n",
        "        with open(os.path.join(output_path, 'insights.txt'), 'w') as f:\n",
        "            f.write(combined_insights)\n",
        "        print(f\"Insights saved to: {os.path.join(output_path, 'insights.txt')}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating insights report: {e}\")\n",
        "        print(\"An error occurred, and the insights report could not be generated.\")\n",
        "\n",
        "# --- Main Script ---\n",
        "if __name__ == \"__main__\":\n",
        "    if not create_output_directory(OUTPUT_PATH):\n",
        "        exit()\n",
        "\n",
        "    # Synthetic dataset (small, embedded in code)\n",
        "    synthetic_dataset = \"\"\"\n",
        "participant_id,group,anxiety_pre,anxiety_post\n",
        "P001,Group A,4,2\n",
        "P002,Group A,3,1\n",
        "P003,Group A,5,3\n",
        "P004,Group B,6,5\n",
        "P005,Group B,5,4\n",
        "P006,Group B,7,6\n",
        "P007,Control,3,3\n",
        "P008,Control,4,4\n",
        "P009,Control,2,2\n",
        "P010,Control,5,5\n",
        "\"\"\"\n",
        "    df = load_data_from_synthetic_string(synthetic_dataset)\n",
        "    is_valid, valid_groups = validate_dataframe(df, [PARTICIPANT_ID_COLUMN, GROUP_COLUMN, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN])\n",
        "    if not is_valid:\n",
        "        exit()\n",
        "\n",
        "    print(\"Original DataFrame Head:\\n\", df.head())\n",
        "\n",
        "    # Keep the original group for plots\n",
        "    df_original_group = df[GROUP_COLUMN].copy()\n",
        "\n",
        "    df = pd.get_dummies(df, columns=[GROUP_COLUMN], prefix=GROUP_COLUMN, drop_first=False) # One-hot encode group, keep all groups\n",
        "    print(\"\\nDataFrame Columns After One-Hot Encoding:\\n\", df.columns)\n",
        "    encoded_group_cols = [col for col in df.columns if col.startswith(f\"{GROUP_COLUMN}_\")]\n",
        "\n",
        "    # Add back the original group (with a new name)\n",
        "    df['original_group'] = df_original_group\n",
        "\n",
        "    # --- DDQN Agent Placeholder ---\n",
        "    # Example state and action space (adapt to your needs)\n",
        "    state_dim = len(encoded_group_cols) + 1 # Example: one-hot encoded groups + anxiety_pre\n",
        "    action_dim = 3 # Example: increase_intervention, decrease_intervention, maintain_intervention\n",
        "    agent = DDQNAgent(state_dim, action_dim)\n",
        "\n",
        "    # Example usage (replace with actual environment interaction)\n",
        "    sample_state = df[encoded_group_cols + [ANXIETY_PRE_COLUMN]].iloc[-1].values # Example state (last row features)\n",
        "    action = agent.act(np.argmax(sample_state)) # Get action for the state\n",
        "    print(f\"\\nDDQN Agent Action (Placeholder): {action}\") # Output the action\n",
        "\n",
        "\n",
        "    df = scale_data(df, [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN] + encoded_group_cols) # Scale data\n",
        "    if df is None:\n",
        "        exit()\n",
        "\n",
        "    shap_feature_columns = encoded_group_cols + [ANXIETY_PRE_COLUMN]\n",
        "    shap_analysis_info = calculate_shap_values(df.copy(), shap_feature_columns, ANXIETY_POST_COLUMN, OUTPUT_PATH) # SHAP analysis - Core focus\n",
        "\n",
        "    neon_colors = [\"#FF00FF\", \"#00FFFF\", \"#FFFF00\", \"#00FF00\"] # Visualization colors\n",
        "    kde_plot_desc = create_kde_plot(df, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors[:2])\n",
        "    violin_plot_desc = create_violin_plot(df, 'original_group', ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors) # Pass original group column\n",
        "    parallel_coords_desc = create_parallel_coordinates_plot(df, 'original_group', ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors) # Pass original group column\n",
        "    hypergraph_desc = visualize_hypergraph(df, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, neon_colors[:2])\n",
        "\n",
        "    bootstrap_ci = perform_bootstrap(df[ANXIETY_POST_COLUMN], np.mean) # Bootstrap analysis\n",
        "    summary_stats_text = save_summary(df, bootstrap_ci, OUTPUT_PATH)\n",
        "\n",
        "    generate_insights_report(summary_stats_text, shap_analysis_info, kde_plot_desc, violin_plot_desc, parallel_coords_desc, hypergraph_desc, OUTPUT_PATH) # Generate report\n",
        "\n",
        "    print(\"Execution completed successfully - SHAP Feature Importance Enhanced Notebook.\")\n"
      ]
    }
  ]
}